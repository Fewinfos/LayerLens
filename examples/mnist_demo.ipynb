{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74662910",
   "metadata": {},
   "source": [
    "# LayerLens MNIST Demo\n",
    "\n",
    "This notebook demonstrates how to use LayerLens to explain a CNN model trained on the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee10e0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Import LayerLens\n",
    "import sys\n",
    "sys.path.append('..')  # Add parent directory to path\n",
    "import layerlens as ll\n",
    "from layerlens.utils import load_sample_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460e04be",
   "metadata": {},
   "source": [
    "## 1. Load the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4c3a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize pixel values\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# Reshape for CNN input (add channel dimension)\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "print(f\"Training data shape: {x_train.shape}\")\n",
    "print(f\"Test data shape: {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54066aab",
   "metadata": {},
   "source": [
    "## 2. Create a simple CNN model for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2345a973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a simple CNN model\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1), name='conv1'),\n",
    "    layers.MaxPooling2D((2, 2), name='pool1'),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', name='conv2'),\n",
    "    layers.MaxPooling2D((2, 2), name='pool2'),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', name='conv3'),\n",
    "    layers.Flatten(name='flatten'),\n",
    "    layers.Dense(64, activation='relu', name='dense1'),\n",
    "    layers.Dense(10, activation='softmax', name='output')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Display model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5699e1",
   "metadata": {},
   "source": [
    "## 3. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e7edfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model (or load pre-trained weights if available)\n",
    "try:\n",
    "    model.load_weights('mnist_cnn.h5')\n",
    "    print(\"Loaded pre-trained weights\")\n",
    "except:\n",
    "    print(\"Training the model...\")\n",
    "    model.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
    "    model.save_weights('mnist_cnn.h5')\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f'Test accuracy: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727fec2f",
   "metadata": {},
   "source": [
    "## 4. Use LayerLens to explain the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68775764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LayerLens explainer\n",
    "explainer = ll.Explainer(model)\n",
    "\n",
    "# Select a sample image to explain\n",
    "sample_idx = 42\n",
    "sample_image = x_test[sample_idx:sample_idx+1]\n",
    "sample_label = np.argmax(y_test[sample_idx])\n",
    "\n",
    "# Display the sample image\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(sample_image[0, :, :, 0], cmap='gray')\n",
    "plt.title(f\"Digit: {sample_label}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Generate explanations\n",
    "explanations = explainer.explain(sample_image)\n",
    "\n",
    "print(f\"Generated explanations for {len(explanations.layer_explanations)} layers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909b0505",
   "metadata": {},
   "source": [
    "## 5. Visualize layer activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e36f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract layer outputs\n",
    "from layerlens.core.layer_extractor import LayerExtractor\n",
    "\n",
    "extractor = LayerExtractor(model)\n",
    "layer_outputs = extractor.extract(sample_image)\n",
    "\n",
    "# Visualize activations for the first convolutional layer\n",
    "from layerlens.visualization.heatmap_generator import generate_heatmap\n",
    "\n",
    "conv1_activations = layer_outputs['conv1']\n",
    "conv1_heatmap = generate_heatmap(conv1_activations, 'conv1', sample_image[0], overlay=False)\n",
    "\n",
    "# Display the heatmap\n",
    "from plotly.offline import iplot\n",
    "iplot(conv1_heatmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fdafa1",
   "metadata": {},
   "source": [
    "## 6. Build surrogate models for each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab29211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build surrogate models\n",
    "from layerlens.core.surrogate_builder import SurrogateBuilder\n",
    "\n",
    "surrogate_builder = SurrogateBuilder(surrogate_type='tree')\n",
    "\n",
    "# Get a larger sample for training surrogates\n",
    "n_samples = 200\n",
    "sample_indices = np.random.choice(len(x_test), n_samples, replace=False)\n",
    "sample_data = x_test[sample_indices]\n",
    "\n",
    "# Extract layer outputs for all samples\n",
    "all_layer_outputs = extractor.extract(sample_data)\n",
    "\n",
    "# Build surrogate for the first dense layer\n",
    "dense1_outputs = all_layer_outputs['dense1']\n",
    "dense1_surrogate = surrogate_builder.fit('dense1', sample_data.reshape(n_samples, -1), dense1_outputs)\n",
    "\n",
    "# Evaluate the surrogate\n",
    "from layerlens.utils.plot_utils import plot_surrogate_vs_original\n",
    "\n",
    "# Predict with both the surrogate and the original layer\n",
    "surrogate_preds = dense1_surrogate.predict(sample_data.reshape(n_samples, -1))\n",
    "original_preds = all_layer_outputs['dense1']\n",
    "\n",
    "# Plot the comparison\n",
    "surrogate_vs_original_fig = plot_surrogate_vs_original(\n",
    "    surrogate_preds, original_preds, \n",
    "    title=\"Dense Layer 1: Surrogate vs Original\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f528bf41",
   "metadata": {},
   "source": [
    "## 7. Analyze feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab4a208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances from the surrogate model\n",
    "if hasattr(dense1_surrogate, 'feature_importances_'):\n",
    "    feature_importances = dense1_surrogate.feature_importances_\n",
    "    \n",
    "    # Plot top feature importances\n",
    "    from layerlens.utils.plot_utils import plot_feature_importance\n",
    "    \n",
    "    importance_fig = plot_feature_importance(\n",
    "        feature_importances, \n",
    "        feature_names=None,  # Use default feature names\n",
    "        top_n=20  # Show top 20 features\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e659dac",
   "metadata": {},
   "source": [
    "## 8. Visualize the model graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8dcbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the model architecture\n",
    "from layerlens.visualization.layer_graph import plot_layer_graph\n",
    "\n",
    "# Create the graph visualization\n",
    "layer_graph = plot_layer_graph(model, highlight_layers='dense1')\n",
    "\n",
    "# Display the graph\n",
    "iplot(layer_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a6fcf8",
   "metadata": {},
   "source": [
    "## 9. Use the dashboard for interactive exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1638e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an interactive dashboard (this will open a new browser tab)\n",
    "from layerlens.visualization.dashboard import show_dashboard\n",
    "\n",
    "# Uncomment to run the dashboard\n",
    "# show_dashboard(explanations, port=8050)\n",
    "print(\"To launch the dashboard, uncomment the line above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1458b234",
   "metadata": {},
   "source": [
    "## 10. Explore feature flow through the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10e8102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize how features flow through the network\n",
    "from layerlens.visualization.feature_flow import plot_feature_flow\n",
    "\n",
    "# Create the feature flow visualization\n",
    "feature_flow_fig = plot_feature_flow(explanations, sample_image)\n",
    "\n",
    "# Display the visualization\n",
    "iplot(feature_flow_fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76cc0a6",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've demonstrated how to use LayerLens to:\n",
    "\n",
    "1. Extract layer activations from a CNN model\n",
    "2. Build interpretable surrogate models for layers\n",
    "3. Visualize activations and feature importances\n",
    "4. Explore the model's structure and behavior\n",
    "\n",
    "LayerLens provides a comprehensive toolkit for understanding how deep learning models make decisions by analyzing the behavior of individual layers."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
